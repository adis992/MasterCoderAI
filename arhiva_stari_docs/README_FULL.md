# ğŸ¤– MasterCoderAI - Full Documentation

**Version:** 2.0.0  
**Release Date:** January 24, 2026  
**Status:** âœ… Production Ready (Minor features pending)

---

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Features](#features)
3. [Architecture](#architecture)
4. [Installation](#installation)
5. [Usage](#usage)
6. [API Documentation](#api-documentation)
7. [Completed Features](#completed-features)
8. [Pending Features](#pending-features)
9. [Future Roadmap](#future-roadmap)
10. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Overview

**MasterCoderAI** je potpuno funkcionalna AI chat platforma sa GPU akceleracijom, lokalnim LLM modelima (llama.cpp), i modernim React frontend-om. Sistem podrÅ¾ava multi-user okruÅ¾enje, admin panel, i real-time monitoring GPU-a.

### Key Highlights:
- âœ… **100% Uncensored** AI responses (DarkIdol Llama 3.1)
- âœ… Multi-GPU support (NVIDIA CUDA)
- âœ… Real-time system monitoring
- âœ… Persistent chat history
- âœ… Role-based access control (Admin/User)
- âœ… Complete REST API
- âœ… Responsive UI (Desktop/Mobile)

---

## ğŸš€ Features

### âœ… Completed Features

#### Frontend (React)
- [x] Modern responsive UI with dark theme
- [x] Real-time GPU monitoring (3sec refresh)
- [x] System health dashboard
- [x] Chat interface sa:
  - [x] Image upload support
  - [x] Message editing & resending
  - [x] Copy to clipboard (HTTP fallback)
  - [x] Like/Rating system (1-3 stars)
  - [x] Download chat history
  - [x] Auto-scroll to latest message
  - [x] Persistent state (F5 refresh remembers tab & history)
- [x] Admin panel sa:
  - [x] User management (CRUD)
  - [x] Database viewer
  - [x] Model management
  - [x] System settings
  - [x] All chats history sidebar
  - [x] Export all chats funkcija
  - [x] Delete individual chats
- [x] Proper initialization flow (step-by-step loading screen)
- [x] Token expiration handling
- [x] Session persistence (30min inactivity logout)

#### Backend (FastAPI + Python)
- [x] JWT authentication
- [x] Role-based authorization (admin/user)
- [x] SQLite database (async)
- [x] llama-cpp-python integration
- [x] Multi-GPU support
- [x] Model auto-load on startup
- [x] System metrics (CPU, RAM, Disk, GPU)
- [x] Chat history storage
- [x] User settings (temperature, max_tokens, etc.)
- [x] CORS enabled (LAN access)
- [x] Uncensored mode (default)
- [x] Web search integration (optional)

#### Models
- [x] DarkIdol Llama 3.1 8B Uncensored (Q8_0.gguf - 8.5GB)
- [x] Auto GPU offload (100% layers)
- [x] Streaming support
- [x] Context window: 8192 tokens

#### Infrastructure
- [x] Shell scripts za easy deployment
- [x] Auto-install dependencies
- [x] Background process management
- [x] Logging sistema
- [x] Health checks

---

## ğŸ—ï¸ Architecture

```
MasterCoderAI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI app
â”‚   â”‚   â”œâ”€â”€ auth.py          # JWT authentication
â”‚   â”‚   â”œâ”€â”€ ai.py            # LLM integration
â”‚   â”‚   â”œâ”€â”€ admin.py         # Admin endpoints
â”‚   â”‚   â”œâ”€â”€ user.py          # User endpoints
â”‚   â”‚   â”œâ”€â”€ system.py        # System monitoring
â”‚   â”‚   â””â”€â”€ models.py        # SQLAlchemy models
â”‚   â””â”€â”€ db/
â”‚       â”œâ”€â”€ database.py      # Database connection
â”‚       â””â”€â”€ models.py        # Database schema
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.js # Main app
â”‚   â”‚   â”‚   â””â”€â”€ Login.js     # Login page
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â””â”€â”€ build/               # Production build
â”œâ”€â”€ modeli/
â”‚   â””â”€â”€ DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q8_0.gguf
â”œâ”€â”€ testiranje/              # Test scripts (isolated)
â”œâ”€â”€ run_all.sh               # Main startup script
â”œâ”€â”€ run.sh                   # Backend only
â”œâ”€â”€ start.sh                 # Alternative startup
â””â”€â”€ stop.sh                  # Shutdown script
```

---

## ğŸ“¦ Installation

### Prerequisites
- Ubuntu/Debian Linux
- Python 3.10+
- Node.js 16+
- NVIDIA GPU (optional but recommended)
- CUDA Toolkit 11.8+ (for GPU)

### Quick Start

```bash
# 1. Clone repository
git clone <repo-url>
cd MasterCoderAI

# 2. Run installation
chmod +x run_all.sh
./run_all.sh

# 3. Access aplikacije
# Frontend: http://localhost:3000
# Backend API: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

### Manual Installation

```bash
# Backend
cd backend
pip install -r requirements.txt

# Frontend
cd frontend
npm install
npm run build

# Start services
cd ..
./run.sh  # Backend
# Frontend is served from build/
```

---

## ğŸ’» Usage

### Default Credentials
- **Admin:** `admin` / `admin123`
- **User:** `user` / `user123`

### Admin Features
1. **Dashboard** - System stats, GPU monitoring
2. **Models** - Load/unload AI models
3. **Users** - Add/edit/delete users
4. **Database** - Direct database access
5. **System** - Settings & configuration
6. **Chat History** - View/delete/export all chats

### User Features
1. **Chat** - Talk to AI
2. **Settings** - Customize AI parameters

### Model Loading
1. Go to **Models** tab
2. Select model from dropdown
3. Click **Load to GPU**
4. Wait 1-2 minutes for initialization
5. Green status = ready to chat!

---

## ğŸ“¡ API Documentation

### Authentication Endpoints

#### POST `/auth/login`
Login user and get JWT token.

**Request:**
```json
{
  "username": "admin",
  "password": "admin123"
}
```

**Response:**
```json
{
  "access_token": "eyJ...",
  "token_type": "bearer"
}
```

### AI Endpoints

#### POST `/ai/chat`
Send message to AI and get response.

**Headers:**
```
Authorization: Bearer <token>
```

**Request:**
```json
{
  "message": "Hello AI!",
  "save_to_history": true
}
```

**Response:**
```json
{
  "message": "Hello AI!",
  "response": "Hello! How can I help you today?",
  "model_name": "DarkIdol-Llama-3.1...",
  "saved": true,
  "uncensored": true
}
```

#### GET `/ai/models`
List all available models.

#### POST `/ai/models/load`
Load model to GPU.

#### GET `/ai/gpu`
Get GPU status and metrics.

### Admin Endpoints

#### GET `/admin/users`
List all users (admin only).

#### GET `/admin/chats`
Get all chat history (admin only).

#### DELETE `/admin/chats/{chat_id}`
Delete specific chat (admin only).

### System Endpoints

#### GET `/system/health`
System health check.

#### GET `/system/settings`
Get system settings.

Full API docs: `http://localhost:8000/docs`

---

## âœ… Completed Features (v2.0.0)

### Core Functionality
- âœ… Multi-user authentication
- âœ… Admin panel
- âœ… Model loading to GPU
- âœ… Real-time chat with AI
- âœ… Chat history persistence
- âœ… GPU monitoring
- âœ… System health monitoring

### UI/UX
- âœ… Responsive design
- âœ… Dark theme
- âœ… Loading screens
- âœ… Error handling
- âœ… Clipboard support (HTTP fallback)
- âœ… Auto-scroll chat
- âœ… Persistent state (F5)
- âœ… Like/rating system

### Admin Tools
- âœ… User management
- âœ… Database viewer
- âœ… Chat history sidebar
- âœ… Export chats
- âœ… Delete chats
- âœ… System settings

### Backend
- âœ… JWT authentication
- âœ… Database migrations
- âœ… Model auto-load
- âœ… CORS support
- âœ… Streaming responses
- âœ… Error logging

---

## â³ Pending Features

### Minor Improvements Needed:
- [ ] Chat rename functionality (sidebar)
- [ ] Background initialization (no panel refresh)
- [ ] Web search toggle UI
- [ ] Prompt mode selector UI
- [ ] Theme selection (currently dark only)
- [ ] Mobile menu improvements
- [ ] Image upload in chat (backend ready, UI needs polish)

### Known Issues:
- âš ï¸ Clipboard API requires HTTPS (fallback implemented)
- âš ï¸ Initialization sometimes refreshes panel (cosmetic)
- âš ï¸ Large chat histories slow down UI (need pagination)

---

## ğŸ”® Future Roadmap

### v2.1 (Next Release)
- [ ] Chat rename functionality
- [ ] Background initialization fix
- [ ] Pagination for chat history
- [ ] Better mobile responsiveness
- [ ] Theme switcher (light/dark)
- [ ] User profile pages
- [ ] Password change functionality

### v2.2 (Planned)
- [ ] Multi-model chat (compare responses)
- [ ] Voice input/output
- [ ] Document upload & RAG
- [ ] Custom prompt templates
- [ ] API rate limiting
- [ ] Webhooks support

### v3.0 (Future)
- [ ] Multi-language support
- [ ] Plugin system
- [ ] Docker deployment
- [ ] Kubernetes support
- [ ] Redis caching
- [ ] PostgreSQL migration
- [ ] Real-time collaboration
- [ ] Mobile app (React Native)

---

## ğŸ› Troubleshooting

### Model won't load
```bash
# Check GPU availability
nvidia-smi

# Check model file
ls -lh /root/MasterCoderAI/modeli/

# Check backend logs
tail -f /tmp/backend.log
```

### Chat returns "Network Error"
```bash
# Check if backend is running
curl http://localhost:8000/health

# Restart backend
./stop.sh && ./run.sh
```

### Login fails
```bash
# Reset admin password
cd backend
python3 -c "
from werkzeug.security import generate_password_hash
import sqlite3
conn = sqlite3.connect('data.db')
hash = generate_password_hash('admin123')
conn.execute('UPDATE users SET hashed_password=? WHERE username=\"admin\"', (hash,))
conn.commit()
print('Password reset!')
"
```

### GPU not detected
```bash
# Install CUDA
sudo apt install nvidia-cuda-toolkit

# Reinstall llama-cpp-python with GPU
pip uninstall llama-cpp-python -y
CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python --no-cache-dir
```

---

## ğŸ“„ License

Proprietary - All Rights Reserved

---

## ğŸ‘¥ Credits

- **LLM Engine:** llama.cpp
- **Model:** DarkIdol Llama 3.1 Uncensored
- **Frontend:** React 18
- **Backend:** FastAPI
- **Database:** SQLite (async)

---

## ğŸ“ Support

For issues or questions, check logs:
- Backend: `/tmp/backend.log`
- Browser: Console (F12)
- System: `/var/log/syslog`

---

**Last Updated:** January 24, 2026  
**Maintained by:** MasterCoderAI Team
